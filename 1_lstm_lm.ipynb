{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_lm.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIYdn1woOS1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3965c71f-648a-4aac-c333-70f873931a80"
      },
      "source": [
        "!pip install torch==1.9 torchtext==0.10"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.9 in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: torchtext==0.10 in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9) (3.7.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV9Cis3HdHp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0553b4cd-998a-48dd-9eb6-be5f4fded814"
      },
      "source": [
        "!pip install datasets"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.6.0)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaD4Nk85FsZc"
      },
      "source": [
        "import math\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "\n",
        "import tqdm\n",
        "\n",
        "import datasets"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1dT3x9ZFt-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a6b2ae-1ebb-4973-dcc1-09793321024d"
      },
      "source": [
        "print(torch.__version__)\n",
        "print(torchtext.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.9.0+cu102\n",
            "0.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djyFDC4QFwVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af81c2cc-28b0-4197-b866-3971f2f74872"
      },
      "source": [
        "dataset = datasets.load_dataset('wikitext', 'wikitext-2-raw-v1')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B_uOuSTF0PU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1231e457-de91-4edd-a372-025f641e93d1"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    test: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 4358\n",
              "    })\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 36718\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 3760\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5QwnBkTcfNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20e07ef9-0631-45ec-f20f-6aba170b32d0"
      },
      "source": [
        "dataset['train'][0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ''}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp-LECVmcgSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7d84060-115c-44d8-958a-969b937114ca"
      },
      "source": [
        "dataset['train'][1]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ' = Valkyria Chronicles III = \\n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKcltvAsfgHW"
      },
      "source": [
        "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCJYUEGrfxo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43bf0671-aefb-4823-8dc1-bef681054b0b"
      },
      "source": [
        "tokenizer('hello world how are you?')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'world', 'how', 'are', 'you', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4ipPKSwf0jq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7256c000-a91e-4904-ee9d-ceb4c6a9684f"
      },
      "source": [
        "tokenizer(dataset['train'][1]['text'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['=', 'valkyria', 'chronicles', 'iii', '=']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aODmmThhcpTx"
      },
      "source": [
        "def tokenize_data(example, tokenizer):\n",
        "    tokens = {'tokens': tokenizer(example['text'])}\n",
        "    return tokens"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5x9lbSFc5Yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02989f00-fd8d-47f4-e227-bec992d5c2de"
      },
      "source": [
        "tokenized_dataset = dataset.map(tokenize_data, remove_columns=['text'], fn_kwargs={'tokenizer': tokenizer})"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-ad820ce433d49621.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-677f66b38513724d.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-3eb0562c08f69ed1.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcGF9LYAiEqB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dff3e2d-3c1b-457f-b49b-989ce6744b67"
      },
      "source": [
        "tokenized_dataset['train'][1]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tokens': ['=', 'valkyria', 'chronicles', 'iii', '=']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c1NIY8yiHJo"
      },
      "source": [
        "vocab = torchtext.vocab.build_vocab_from_iterator(tokenized_dataset['train']['tokens'],\n",
        "                                                  min_freq=3)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9onJczdaiq1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2dfe63-6501-46fa-ab66-0aa89d15c83e"
      },
      "source": [
        "vocab.get_itos()[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', ',', '.', 'of', 'and', 'in', 'to', 'a', '=', 'was']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzS26a0GIERG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "895996fa-a5f6-4df6-d99e-1e6b8bc74e52"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29471"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUSGIDkP_YvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4c5e908-0156-4b6f-c114-6ef5f76642bd"
      },
      "source": [
        "'hello' in vocab"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54CbiCkw_5P3"
      },
      "source": [
        "vocab.insert_token('<unk>', 0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTNbJipk_k5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a4d20b2-3139-4966-c346-9b33680e17c3"
      },
      "source": [
        "vocab.get_itos()[:10]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', 'the', ',', '.', 'of', 'and', 'in', 'to', 'a', '=']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grwHG5UN_eKN"
      },
      "source": [
        "vocab.set_default_index(0)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_JUTdrJ_m7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e9876f9-5caa-43b2-c003-f04e977ae100"
      },
      "source": [
        "vocab['hello']"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYKf-779yFCB"
      },
      "source": [
        "vocab.insert_token('<eos>', 1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtYdBoybyI9B",
        "outputId": "dc3a49e7-4ebb-465d-f249-9b2f02884570"
      },
      "source": [
        "vocab.get_itos()[:10]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<eos>', 'the', ',', '.', 'of', 'and', 'in', 'to', 'a']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMUwATIrwkAi"
      },
      "source": [
        "def get_data(dataset, vocab, batch_size):\n",
        "    data = []\n",
        "    for example in dataset:\n",
        "        if example['tokens']:\n",
        "            tokens = example['tokens'].append('<eos>')\n",
        "            tokens = [vocab[token] for token in example['tokens']]\n",
        "            data.extend(tokens)\n",
        "    data = torch.LongTensor(data)\n",
        "    n_batches = data.shape[0] // batch_size\n",
        "    data = data.narrow(0, 0, n_batches * batch_size)\n",
        "    data = data.view(batch_size, -1)\n",
        "    return data"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtjtIvuNisST"
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_data = get_data(tokenized_dataset['train'], vocab, batch_size)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsmojuCbivzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "313df82d-d286-4198-fcbe-868abd907f41"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 16214])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "038OtCf3hbeY"
      },
      "source": [
        "valid_data = get_data(tokenized_dataset['validation'], vocab, batch_size)\n",
        "test_data = get_data(tokenized_dataset['test'], vocab, batch_size)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAKBc-UUjO0-"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, dropout_rate, tie_weights):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout_rate, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "        init_range = 0.1\n",
        "        self.embedding.weight.data.uniform_(-init_range, init_range)\n",
        "        self.fc.weight.data.uniform_(-init_range, init_range)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "        if tie_weights:\n",
        "            assert embedding_dim == hidden_dim, 'If tying weights then embedding_dim must equal hidden_dim'\n",
        "            self.embedding.weight = self.fc.weight\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "    \n",
        "    def init_hidden(self, batch_size, device):\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
        "        cell = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
        "        return hidden, cell\n",
        "\n",
        "    def detach_hidden(self, hidden):\n",
        "        hidden, cell = hidden\n",
        "        hidden = hidden.detach()\n",
        "        cell = cell.detach()\n",
        "        return hidden, cell\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        # input = [batch size, seq len]\n",
        "        # hidden = [n layers, batch size, hidden dim]\n",
        "        embedding = self.dropout(self.embedding(input))\n",
        "        # embedding = [batch size, seq len, embedding dim]\n",
        "        output, hidden = self.lstm(embedding, hidden)\n",
        "        # output = [batch size, seq len, hidden dim]\n",
        "        # hidden = [n layers, batch size, hidden dim]\n",
        "        output = self.dropout(output)\n",
        "        output = self.fc(output)\n",
        "        # output = [batch size, seq len, vocab size]\n",
        "        return output, hidden"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBYYhJ3WjWpY"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 1024\n",
        "hidden_dim = 1024\n",
        "n_layers = 2\n",
        "dropout_rate = 0.5\n",
        "tie_weights = True\n",
        "\n",
        "model = LSTM(vocab_size, embedding_dim, hidden_dim, n_layers, dropout_rate, tie_weights)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C9nTPpxsclE",
        "outputId": "7404f03b-40f0-47e5-ae11-003a39c77c39"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 47,003,425 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXwUDCA-92-y"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkggfxKJBZ04"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMfUy_H2IdUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c2ec05-47e0-4615-8b4d-29f5db01d2cd"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoPhYH3PJB-S"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5omPylb8Kag_"
      },
      "source": [
        "def train(model, data, optimizer, criterion, batch_size, max_seq_len, clip, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    n_tokens = data.shape[-1]\n",
        "\n",
        "    hidden = model.init_hidden(batch_size, device)\n",
        "    \n",
        "    for offset in tqdm.tqdm(range(0, n_tokens - 1, max_seq_len)):\n",
        "        optimizer.zero_grad()\n",
        "        input, target, seq_len = get_batch(data, max_seq_len, n_tokens, offset)\n",
        "        input = input.to(device)\n",
        "        target = target.to(device)\n",
        "        # input = [batch size, seq len]\n",
        "        # target = [batch size, seq len]\n",
        "        hidden = model.detach_hidden(hidden)\n",
        "        # hidden = [n layers, batch size, hidden dim]\n",
        "        output, hidden = model(input, hidden)\n",
        "        # output = [batch size, seq len, vocab size]\n",
        "        # hidden = [n layers, batch size, hidden dim]\n",
        "        output = output.reshape(-1, model.vocab_size)\n",
        "        target = target.reshape(-1)\n",
        "        # output = [batch size * seq len, vocab size]\n",
        "        # target = [batch size * seq len]\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item() * seq_len\n",
        "    return epoch_loss / n_tokens"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iikSU_1YT0dV"
      },
      "source": [
        "def get_batch(data, max_seq_len, n_tokens, offset):\n",
        "    seq_len = min(max_seq_len, n_tokens - offset - 1)\n",
        "    input = data[:, offset:offset+seq_len]\n",
        "    target = data[:, offset+1:offset+seq_len+1]\n",
        "    return input, target, seq_len"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ev0pAlFMAgH"
      },
      "source": [
        "def evaluate(model, data, criterion, batch_size, max_seq_len, device):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    model.eval()\n",
        "    n_tokens = data.shape[-1]\n",
        "\n",
        "    hidden = model.init_hidden(batch_size, device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for offset in tqdm.tqdm(range(0, n_tokens - 1, max_seq_len)):\n",
        "            input, target, seq_len = get_batch(data, max_seq_len, n_tokens, offset)\n",
        "            input = input.to(device)\n",
        "            target = target.to(device)\n",
        "            # input = [batch size, seq len]\n",
        "            # target = [batch size, seq len]\n",
        "            hidden = model.detach_hidden(hidden)\n",
        "            # hidden = [n layers, batch size, hidden dim]\n",
        "            output, hidden = model(input, hidden)\n",
        "            # output = [batch size, seq len, vocab size]\n",
        "            # hidden = [n layers, batch size, hidden dim]\n",
        "            output = output.reshape(-1, model.vocab_size)\n",
        "            target = target.reshape(-1)\n",
        "            # output = [batch size * seq len, vocab size]\n",
        "            # target = [batch size * seq len]\n",
        "            loss = criterion(output, target)\n",
        "            epoch_loss += loss.item() * seq_len\n",
        "    return epoch_loss / n_tokens"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_qDt7hWi3wJ"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q6owq2DwP9Y"
      },
      "source": [
        "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=0)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYVEjus7MElw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34cf3ce3-9672-445e-a856-7bd67d3c8556"
      },
      "source": [
        "n_epochs = 50\n",
        "max_seq_len = 50\n",
        "clip = 0.25\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    start_time = time.monotonic()\n",
        "\n",
        "    train_loss = train(model, train_data, optimizer, criterion, batch_size, max_seq_len, clip, device)\n",
        "    valid_loss = evaluate(model, valid_data, criterion, batch_size, max_seq_len, device)\n",
        "    \n",
        "    lr_scheduler.step(valid_loss)\n",
        "\n",
        "    end_time = time.monotonic()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'lstm_lm.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(train_loss, valid_loss)\n",
        "    try:\n",
        "        print(f'\\tTrain Perplexity: {math.exp(train_loss):.3f}')\n",
        "        print(f'\\tValid Perplexity: {math.exp(valid_loss):.3f}')\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.75it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.80it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 29s\n",
            "6.319018106300587 5.519182275769846\n",
            "\tTrain Perplexity: 555.028\n",
            "\tValid Perplexity: 249.431\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.75it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.79it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 02 | Epoch Time: 1m 29s\n",
            "5.504364474569368 5.166163277232422\n",
            "\tTrain Perplexity: 245.762\n",
            "\tValid Perplexity: 175.241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.75it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.81it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 03 | Epoch Time: 1m 29s\n",
            "5.128028552011951 4.964524977049738\n",
            "\tTrain Perplexity: 168.684\n",
            "\tValid Perplexity: 143.240\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.75it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.81it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 04 | Epoch Time: 1m 29s\n",
            "4.87150282187513 4.864466262032401\n",
            "\tTrain Perplexity: 130.517\n",
            "\tValid Perplexity: 129.602\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.76it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.81it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 05 | Epoch Time: 1m 29s\n",
            "4.674903718290309 4.795204275902712\n",
            "\tTrain Perplexity: 107.222\n",
            "\tValid Perplexity: 120.929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.75it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.80it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 06 | Epoch Time: 1m 29s\n",
            "4.513384941636788 4.755957411988726\n",
            "\tTrain Perplexity: 91.230\n",
            "\tValid Perplexity: 116.275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.75it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.80it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 07 | Epoch Time: 1m 29s\n",
            "4.377365114304498 4.731894555800366\n",
            "\tTrain Perplexity: 79.628\n",
            "\tValid Perplexity: 113.510\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.75it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.80it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 08 | Epoch Time: 1m 29s\n",
            "4.2609077138849 4.710101452919672\n",
            "\tTrain Perplexity: 70.874\n",
            "\tValid Perplexity: 111.063\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.74it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.80it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 09 | Epoch Time: 1m 29s\n",
            "4.1550633080337676 4.691102170156983\n",
            "\tTrain Perplexity: 63.756\n",
            "\tValid Perplexity: 108.973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.75it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.80it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10 | Epoch Time: 1m 29s\n",
            "4.064859563168871 4.696503576805007\n",
            "\tTrain Perplexity: 58.257\n",
            "\tValid Perplexity: 109.563\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.74it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.79it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 11 | Epoch Time: 1m 29s\n",
            "3.938319919949559 4.668287265132058\n",
            "\tTrain Perplexity: 51.332\n",
            "\tValid Perplexity: 106.515\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.75it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.81it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 12 | Epoch Time: 1m 29s\n",
            "3.873365554045525 4.668153247462128\n",
            "\tTrain Perplexity: 48.104\n",
            "\tValid Perplexity: 106.501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.74it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.80it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 13 | Epoch Time: 1m 29s\n",
            "3.8073581532425043 4.659371532078059\n",
            "\tTrain Perplexity: 45.031\n",
            "\tValid Perplexity: 105.570\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.75it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.80it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 14 | Epoch Time: 1m 29s\n",
            "3.7751283205083404 4.6565974756794155\n",
            "\tTrain Perplexity: 43.603\n",
            "\tValid Perplexity: 105.277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.74it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.79it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 15 | Epoch Time: 1m 29s\n",
            "3.7484675003536183 4.657219166182122\n",
            "\tTrain Perplexity: 42.456\n",
            "\tValid Perplexity: 105.343\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.74it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.81it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 16 | Epoch Time: 1m 29s\n",
            "3.7206377328155336 4.655619622120318\n",
            "\tTrain Perplexity: 41.291\n",
            "\tValid Perplexity: 105.174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.74it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.79it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 17 | Epoch Time: 1m 29s\n",
            "3.704745521744803 4.655130551952236\n",
            "\tTrain Perplexity: 40.640\n",
            "\tValid Perplexity: 105.123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.74it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.80it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 18 | Epoch Time: 1m 29s\n",
            "3.6915810806059848 4.653878013761538\n",
            "\tTrain Perplexity: 40.108\n",
            "\tValid Perplexity: 104.991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.75it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.80it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 19 | Epoch Time: 1m 29s\n",
            "3.6784542358302446 4.653350665884198\n",
            "\tTrain Perplexity: 39.585\n",
            "\tValid Perplexity: 104.936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.74it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.80it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 20 | Epoch Time: 1m 29s\n",
            "3.663888674710496 4.654044960186167\n",
            "\tTrain Perplexity: 39.013\n",
            "\tValid Perplexity: 105.009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.75it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.80it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 21 | Epoch Time: 1m 29s\n",
            "3.6531921933490454 4.6530894414996204\n",
            "\tTrain Perplexity: 38.598\n",
            "\tValid Perplexity: 104.909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.74it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.80it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 22 | Epoch Time: 1m 29s\n",
            "3.653313026896414 4.651648295375536\n",
            "\tTrain Perplexity: 38.602\n",
            "\tValid Perplexity: 104.758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.74it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.81it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 23 | Epoch Time: 1m 29s\n",
            "3.6486361762282438 4.6479863012736695\n",
            "\tTrain Perplexity: 38.422\n",
            "\tValid Perplexity: 104.375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.75it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.80it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 24 | Epoch Time: 1m 29s\n",
            "3.642663696095434 4.64893360604655\n",
            "\tTrain Perplexity: 38.193\n",
            "\tValid Perplexity: 104.474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.74it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.79it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 25 | Epoch Time: 1m 29s\n",
            "3.650525539683343 4.640818731683605\n",
            "\tTrain Perplexity: 38.495\n",
            "\tValid Perplexity: 103.629\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.75it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.81it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 26 | Epoch Time: 1m 29s\n",
            "3.650938940927546 4.641147354301417\n",
            "\tTrain Perplexity: 38.511\n",
            "\tValid Perplexity: 103.663\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.74it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.80it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 27 | Epoch Time: 1m 29s\n",
            "3.652521930509068 4.641891875356998\n",
            "\tTrain Perplexity: 38.572\n",
            "\tValid Perplexity: 103.740\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.74it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.80it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 28 | Epoch Time: 1m 29s\n",
            "3.6615614594021575 4.64130736887455\n",
            "\tTrain Perplexity: 38.922\n",
            "\tValid Perplexity: 103.680\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 325/325 [01:26<00:00,  3.74it/s]\n",
            "100%|██████████| 34/34 [00:02<00:00, 11.79it/s]\n",
            "  0%|          | 0/325 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 29 | Epoch Time: 1m 29s\n",
            "3.6669943484275396 4.640843982122979\n",
            "\tTrain Perplexity: 39.134\n",
            "\tValid Perplexity: 103.632\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 82/325 [00:21<01:05,  3.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-501fc3a4ce4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-f7c5d9e28f2a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, optimizer, criterion, batch_size, max_seq_len, clip, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# target = [batch size * seq len]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0Y0oNdgRkad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91e1b341-6b19-4896-fd6f-eba4697dfe52"
      },
      "source": [
        "model.load_state_dict(torch.load('lstm_lm.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_data, criterion, batch_size, max_seq_len, device)\n",
        "\n",
        "print(f'Test Perplexity: {math.exp(test_loss):.3f}')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 2/39 [00:00<00:03, 10.75it/s]\u001b[A\n",
            " 10%|█         | 4/39 [00:00<00:03, 10.95it/s]\u001b[A\n",
            " 15%|█▌        | 6/39 [00:00<00:02, 11.12it/s]\u001b[A\n",
            " 21%|██        | 8/39 [00:00<00:02, 11.26it/s]\u001b[A\n",
            " 26%|██▌       | 10/39 [00:00<00:02, 11.34it/s]\u001b[A\n",
            " 31%|███       | 12/39 [00:01<00:02, 11.40it/s]\u001b[A\n",
            " 36%|███▌      | 14/39 [00:01<00:02, 11.46it/s]\u001b[A\n",
            " 41%|████      | 16/39 [00:01<00:01, 11.50it/s]\u001b[A\n",
            " 46%|████▌     | 18/39 [00:01<00:01, 11.53it/s]\u001b[A\n",
            " 51%|█████▏    | 20/39 [00:01<00:01, 11.55it/s]\u001b[A\n",
            " 56%|█████▋    | 22/39 [00:01<00:01, 11.53it/s]\u001b[A\n",
            " 62%|██████▏   | 24/39 [00:02<00:01, 11.53it/s]\u001b[A\n",
            " 67%|██████▋   | 26/39 [00:02<00:01, 11.55it/s]\u001b[A\n",
            " 72%|███████▏  | 28/39 [00:02<00:00, 11.58it/s]\u001b[A\n",
            " 77%|███████▋  | 30/39 [00:02<00:00, 11.58it/s]\u001b[A\n",
            " 82%|████████▏ | 32/39 [00:02<00:00, 11.58it/s]\u001b[A\n",
            " 87%|████████▋ | 34/39 [00:02<00:00, 11.58it/s]\u001b[A\n",
            " 92%|█████████▏| 36/39 [00:03<00:00, 11.59it/s]\u001b[A\n",
            "100%|██████████| 39/39 [00:03<00:00, 11.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Perplexity: 99.358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GexY2GcCRtXu"
      },
      "source": [
        "def generate(prompt, n_gen_tokens, temperature, model, tokenizer, vocab, device):\n",
        "\n",
        "    tokens = tokenizer(prompt)\n",
        "    indices = [vocab[t] for t in tokens]\n",
        "    batch_size = 1\n",
        "    hidden = model.init_hidden(batch_size, device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(n_gen_tokens):\n",
        "            input = torch.LongTensor([indices]).to(device)\n",
        "            output, hidden = model(input, hidden)\n",
        "            probs = torch.softmax(output[:, -1] / temperature, dim=-1) \n",
        "            prediction = torch.multinomial(probs, num_samples=1).item()\n",
        "            indices.append(prediction)\n",
        "\n",
        "    itos = vocab.get_itos()\n",
        "    tokens = [itos[i] for i in indices]\n",
        "    return tokens"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R778iX9gR38L"
      },
      "source": [
        "prompt = 'my favourite color'\n",
        "n_gen_tokens = 25\n",
        "temperature = 1.0\n",
        "\n",
        "generation = generate(prompt, n_gen_tokens, temperature, model, tokenizer, vocab, device)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1MCYs3mR7nm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b2d36f-8e08-42dc-c85e-9ca308395c9d"
      },
      "source": [
        "generation"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my',\n",
              " 'favourite',\n",
              " 'color',\n",
              " ',',\n",
              " 'genius',\n",
              " 'or',\n",
              " 'seductive',\n",
              " ',',\n",
              " 'has',\n",
              " 'to',\n",
              " 'be',\n",
              " 'good',\n",
              " 'for',\n",
              " 'the',\n",
              " 'first',\n",
              " 'time',\n",
              " 'or',\n",
              " 'a',\n",
              " 'classic',\n",
              " 'christmas',\n",
              " 'series',\n",
              " ',',\n",
              " 'as',\n",
              " 'well',\n",
              " 'as',\n",
              " 'the',\n",
              " 'observer',\n",
              " 'below']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpz2dfdcR8mc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87N3LkyVpEIL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbGOerWrpHnc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZLB5jwgpKUQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYNUGi9uy-qr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}