{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scratchpad",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "source": [
        "#!pip install --pre --upgrade torch torchtext -f https://download.pytorch.org/whl/nightly/cu113/torch_nightly.html"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV9Cis3HdHp8"
      },
      "source": [
        "#!pip install datasets"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaD4Nk85FsZc"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "\n",
        "import datasets"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1dT3x9ZFt-N",
        "outputId": "ddd1cd24-3d9a-4988-c4a8-30f6e6c1b7f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(torch.__version__)\n",
        "print(torchtext.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.10.0.dev20210615+cu113\n",
            "0.11.0.dev20210615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djyFDC4QFwVh",
        "outputId": "65407ea1-9ae9-4753-f6e3-4ac99415ff9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset = datasets.load_dataset('wikitext', 'wikitext-2-raw-v1')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B_uOuSTF0PU",
        "outputId": "b55cc217-8e38-4318-b2fa-69aaa8e94e91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    test: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 4358\n",
              "    })\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 36718\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 3760\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5QwnBkTcfNo",
        "outputId": "03bd6ee2-62dd-416f-ce99-4f307e5a8878",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset['train'][0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ''}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp-LECVmcgSt",
        "outputId": "efa5ad7c-d75c-422e-c0f7-04f9cec915f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset['train'][1]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ' = Valkyria Chronicles III = \\n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKcltvAsfgHW"
      },
      "source": [
        "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCJYUEGrfxo6",
        "outputId": "3dd68e53-7afd-4b6c-94f9-9996c75616f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer('hello world how are you?')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'world', 'how', 'are', 'you', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4ipPKSwf0jq",
        "outputId": "9f13faf2-ec61-4444-f0ee-993216840957",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer(dataset['train'][1]['text'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['=', 'valkyria', 'chronicles', 'iii', '=']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aODmmThhcpTx"
      },
      "source": [
        "def tokenize_data(example, tokenizer):\n",
        "    tokens = {'tokens': tokenizer(example['text'])}\n",
        "    return tokens"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5x9lbSFc5Yh",
        "outputId": "651c031c-8c06-450f-9558-65d5c9ff184b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenized_dataset = dataset.map(tokenize_data, remove_columns=['text'], fn_kwargs={'tokenizer': tokenizer})"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-316c581b96145c43.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-6819a857b3aebc54.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20/cache-7dbdcafc7ad864e5.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcGF9LYAiEqB",
        "outputId": "4cf5d3e0-94c8-4ad6-b0f0-6e035867a95b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenized_dataset['train'][1]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tokens': ['=', 'valkyria', 'chronicles', 'iii', '=']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c1NIY8yiHJo"
      },
      "source": [
        "vocab = torchtext.vocab.build_vocab_from_iterator(tokenized_dataset['train']['tokens'],\n",
        "                                                  min_freq=3)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9onJczdaiq1K",
        "outputId": "cee176ed-cdad-4075-e7de-c085e042c78c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab.get_itos()[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', ',', '.', 'of', 'and', 'in', 'to', 'a', '=', 'was']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzS26a0GIERG",
        "outputId": "3988cae4-c003-4a2c-b80d-07058d0b85ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29471"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUSGIDkP_YvP",
        "outputId": "17e9db75-1208-42a9-aada-ab4765070960",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "'hello' in vocab"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54CbiCkw_5P3"
      },
      "source": [
        "vocab.insert_token('<unk>', 0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTNbJipk_k5b",
        "outputId": "ed561006-7967-4bea-cfa8-6b8fdb4519da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab.get_itos()[:10]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', 'the', ',', '.', 'of', 'and', 'in', 'to', 'a', '=']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grwHG5UN_eKN"
      },
      "source": [
        "vocab.set_default_index(0)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_JUTdrJ_m7j",
        "outputId": "5e138798-58c0-4b33-b96b-9cb3c690c99f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab['hello']"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMUwATIrwkAi"
      },
      "source": [
        "def get_data(dataset, vocab, batch_size):\n",
        "    data = []\n",
        "    for example in dataset:\n",
        "        data.extend([vocab[token] for token in example['tokens']])\n",
        "    data = torch.LongTensor(data)\n",
        "    n_batches = data.shape[0] // batch_size\n",
        "    data = data.narrow(0, 0, n_batches * batch_size)\n",
        "    data = data.view(batch_size, -1)\n",
        "    return data"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtjtIvuNisST"
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "train_data = get_data(tokenized_dataset['train'], vocab, batch_size)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsmojuCbivzC",
        "outputId": "f9897bb1-93c5-4bc3-d20c-abaef9b36d99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 8014])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAKBc-UUjO0-"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, dropout_rate, tie_weights):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout_rate)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "        if tie_weights:\n",
        "            assert embedding_dim == hidden_dim, 'If tying weights then embedding_dim must equal hidden_dim'\n",
        "            self.embedding.weight = self.fc.weight\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "    \n",
        "    def init_hidden(self, batch_size, device):\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
        "        cell = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
        "        return hidden, cell\n",
        "\n",
        "    def detach_hidden(self, hidden):\n",
        "        hidden, cell = hidden\n",
        "        hidden = hidden.detach()\n",
        "        cell = cell.detach()\n",
        "        return hidden, cell\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        # input = [batch size, seq len]\n",
        "        # hidden = [n layers, batch size, hidden dim]\n",
        "        embedding = self.dropout(self.embedding(input))\n",
        "        # embedding = [batch size, seq len, embedding dim]\n",
        "        output, hidden = self.lstm(embedding.permute(1, 0, 2), hidden)\n",
        "        # output = [seq len, batch size, hidden dim]\n",
        "        # hidden = [n layers, batch size, hidden dim]\n",
        "        output = self.dropout(output)\n",
        "        output = self.fc(output.permute(1, 0, 2))\n",
        "        # output = [batch size, seq len, vocab size]\n",
        "        return output, hidden"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBYYhJ3WjWpY"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "dropout_rate = 0.25\n",
        "tie_weights = True\n",
        "\n",
        "model = LSTM(vocab_size, embedding_dim, hidden_dim, n_layers, dropout_rate, tie_weights)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXwUDCA-92-y"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkggfxKJBZ04"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMfUy_H2IdUo",
        "outputId": "efc36132-61a0-47f3-9514-cbc8fab84e4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoPhYH3PJB-S"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5omPylb8Kag_"
      },
      "source": [
        "def train(model, data, optimizer, criterion, batch_size, seq_len, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    n_tokens = data.shape[-1]\n",
        "\n",
        "    hidden = model.init_hidden(batch_size, device)\n",
        "    \n",
        "    for offset in range(0, n_tokens - 1, seq_len):\n",
        "        optimizer.zero_grad()\n",
        "        input, target = get_batch(data, seq_len, n_tokens, offset)\n",
        "        input = input.to(device)\n",
        "        target = target.to(device)\n",
        "        # input = [batch size, seq len]\n",
        "        # target = [batch size, seq len]\n",
        "        hidden = model.detach_hidden(hidden)\n",
        "        # hidden = [n layers, batch size, hidden dim]\n",
        "        output, hidden = model(input, hidden)\n",
        "        # output = [batch size, seq len, vocab size]\n",
        "        # hidden = [n layers, batch size, hidden dim]\n",
        "        output = output.reshape(-1, model.vocab_size)\n",
        "        target = target.reshape(-1)\n",
        "        # output = [batch size * seq len, vocab size]\n",
        "        # target = [batch size * seq len]\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / n_tokens"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iikSU_1YT0dV"
      },
      "source": [
        "def get_batch(data, seq_len, n_tokens, offset):\n",
        "    seq_len = min(seq_len, n_tokens - offset - 1)\n",
        "    input = data[:, offset:offset+seq_len]\n",
        "    target = data[:, offset+1:offset+seq_len+1]\n",
        "    return input, target"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ev0pAlFMAgH",
        "outputId": "050c5673-3a2d-439c-8e6c-bf0aa06bb6e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "seq_len = 100\n",
        "\n",
        "train(model, train_data, optimizer, criterion, batch_size, seq_len, device)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([256, 8014])\n",
            "0 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "100 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "200 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "300 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "400 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "500 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "600 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "700 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "800 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "900 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "1000 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "1100 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "1200 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "1300 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "1400 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "1500 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "1600 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "1700 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "1800 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "1900 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "2000 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "2100 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "2200 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "2300 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "2400 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "2500 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "2600 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "2700 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "2800 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "2900 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "3000 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "3100 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "3200 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "3300 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "3400 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "3500 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "3600 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "3700 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "3800 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "3900 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "4000 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "4100 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "4200 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "4300 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "4400 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "4500 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "4600 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "4700 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "4800 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "4900 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "5000 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "5100 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "5200 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "5300 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "5400 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "5500 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "5600 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "5700 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "5800 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "5900 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "6000 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "6100 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "6200 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "6300 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "6400 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "6500 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "6600 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "6700 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "6800 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "6900 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "7000 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "7100 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "7200 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "7300 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "7400 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "7500 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "7600 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "7700 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "7800 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "7900 torch.Size([256, 100]) torch.Size([256, 100])\n",
            "8000 torch.Size([256, 13]) torch.Size([256, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07573742815345667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYVEjus7MElw",
        "outputId": "7b9764f4-f6c5-48dc-b57c-b375948534bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 8014])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0Y0oNdgRkad",
        "outputId": "9b4a3103-a97e-4b00-b414-2b3d319fcee1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = [1,2,3,4,5,6,7,8,9,0]\n",
        "\n",
        "for i in range(0, len(x), 3):\n",
        "    print(i)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "3\n",
            "6\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GexY2GcCRtXu",
        "outputId": "8265dee2-1d89-43e6-cf36-99bbc3c54718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_tokens = train_data.shape[-1]\n",
        "seq_len = 100\n",
        "for i in range(0, n_tokens - 1, seq_len):\n",
        "    print(i)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n",
            "5100\n",
            "5200\n",
            "5300\n",
            "5400\n",
            "5500\n",
            "5600\n",
            "5700\n",
            "5800\n",
            "5900\n",
            "6000\n",
            "6100\n",
            "6200\n",
            "6300\n",
            "6400\n",
            "6500\n",
            "6600\n",
            "6700\n",
            "6800\n",
            "6900\n",
            "7000\n",
            "7100\n",
            "7200\n",
            "7300\n",
            "7400\n",
            "7500\n",
            "7600\n",
            "7700\n",
            "7800\n",
            "7900\n",
            "8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R778iX9gR38L"
      },
      "source": [
        "n_tokens = train_data.shape[-1]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1MCYs3mR7nm",
        "outputId": "708afe48-b981-4744-c2d7-5e7eeee317a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_tokens"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8014"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpz2dfdcR8mc"
      },
      "source": [
        ""
      ],
      "execution_count": 39,
      "outputs": []
    }
  ]
}